{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing utility functions\n",
    "* `list[emoji]` -> `str` \n",
    "* `str` -> `list[emoji]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòãüçû\n",
      "U+1F3B7\n",
      "necktie [EM] chart_increasing.\n",
      "[':necktie:', ':chart_increasing:']\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import ast\n",
    "\n",
    "def emoji_to_unicode(emoji_str):\n",
    "    return ' '.join([f\"U+{ord(char):X}\" for char in emoji_str])\n",
    "\n",
    "def process_emoji_list_to_str(emoji_list):\n",
    "    desc_processed = ' [EM] '.join(desc.strip(':') for desc in emoji_list)\n",
    "    return f\"{desc_processed}.\"\n",
    "\n",
    "def unprocess_emoji_list_from_str(emoji_str):\n",
    "    s = emoji_str[:-1].split(' [EM] ')\n",
    "    return [f\":{desc}:\" for desc in s]\n",
    "\n",
    "def emoji_str_from_description(desc_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a description string containing emoji descriptions into a string of actual emojis.\n",
    "    Args:\n",
    "        desc_str (str): A string containing emoji descriptions separated by ' [EM] '.\n",
    "                        The string is expected to start with \"This is\" and end with a period (\".\").\n",
    "\n",
    "    Returns:\n",
    "        str: A string of emojis corresponding to the descriptions in the input string.\n",
    "\n",
    "    Example:\n",
    "        >>> emoji_str_from_description('This is face_savoring_food [EM] bread.')\n",
    "        'üòãüçû'\n",
    "    \"\"\"\n",
    "    desc_str = desc_str[8:-1]  # Remove \"This is\" at the start and \".\" at the end\n",
    "    desc_list = desc_str.split(' [EM] ')  # Split the string into a list of descriptions\n",
    "    return ''.join([emoji.emojize(f\":{desc}:\") for desc in desc_list])  # Convert descriptions to emojis\n",
    "\n",
    "# write some tests for processing and unprocessingüìà\n",
    "print(emoji_str_from_description('This is face_savoring_food [EM] bread.'))\n",
    "print(emoji_to_unicode('üé∑'))\n",
    "print(process_emoji_list_to_str([':necktie:', ':chart_increasing:']))\n",
    "print(unprocess_emoji_list_from_str(process_emoji_list_to_str([':necktie:', ':chart_increasing:'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import os\n",
    "\n",
    "def generate_csv(input_file_path, output_file_path, img_folder):\n",
    "    with open(input_file_path, newline='', encoding='utf-8') as fin, \\\n",
    "        open(output_file_path, 'w', newline='', encoding='utf-8') as fout:\n",
    "\n",
    "        reader = csv.DictReader(fin)\n",
    "        fieldnames = ['EM', 'EN', 'unicode', 'label', 'strategy', 'image'] # needs to have the same fieldnames in the output csv\n",
    "        writer = csv.DictWriter(fout, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        i = 0\n",
    "        for row in reader:\n",
    "            em = emoji_str_from_description(row['sent1'])\n",
    "            en = ' '.join(row['sent2'].split()[2:])[:-1] \n",
    "            writer.writerow({\n",
    "                'EM': em,\n",
    "                'EN': en,\n",
    "                'unicode': emoji_to_unicode(em),  # Added this to match fieldnames\n",
    "                'label': row['label'],\n",
    "                'strategy': row['strategy'],\n",
    "                'image': os.path.join(img_folder, f\"{i}.png\") \n",
    "            })\n",
    "\n",
    "            i += 1\n",
    "\n",
    "    print(f\"Conversion complete! Output saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete! Output saved to ./generated_img_dataset/train.csv\n",
      "Conversion complete! Output saved to ./generated_img_dataset/test.csv\n",
      "Conversion complete! Output saved to ./generated_img_dataset/val.csv\n"
     ]
    }
   ],
   "source": [
    "csvs_to_generate = [\n",
    "    (os.path.join('.', 'original_ELCo_dataset', 'train.csv'), \n",
    "     os.path.join('.', 'generated_img_dataset', 'train.csv'), \n",
    "     os.path.join('.', 'generated_img_dataset', 'train_google')),\n",
    "\n",
    "    (os.path.join('.', 'original_ELCo_dataset', 'test.csv'), \n",
    "     os.path.join('.', 'generated_img_dataset', 'test.csv'), \n",
    "     os.path.join('.', 'generated_img_dataset', 'test_google')), \n",
    "\n",
    "    (os.path.join('.', 'original_ELCo_dataset', 'val.csv'), \n",
    "     os.path.join('.', 'generated_img_dataset', 'val.csv'), \n",
    "     os.path.join('.', 'generated_img_dataset', 'val_google')),\n",
    "]\n",
    "\n",
    "for input, output, img_folder in csvs_to_generate:\n",
    "    generate_csv(input, output, img_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing numbers in filenames: [26, 42, 375, 376, 488, 544, 566, 622, 630, 638, 1343, 1521, 1523, 1528, 1529, 1530, 1531, 1533, 1534, 1537, 1539, 1541, 1545, 1551, 1553, 1554, 1555, 1556, 1558]\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def count_missing_numbers(folder_path):\n",
    "  # Get a list of all files in the folder\n",
    "  files = os.listdir(folder_path)\n",
    "  \n",
    "  # Extract numbers from filenames and convert them to integers\n",
    "  numbers = sorted([int(f.split('.')[0]) for f in files if f.split('.')[0].isdigit()])\n",
    "  \n",
    "  # Find the missing numbers\n",
    "  missing_numbers = [num for num in range(numbers[0], numbers[-1] + 1) if num not in numbers]\n",
    "  \n",
    "  return missing_numbers\n",
    "\n",
    "folder_path = 'google_dataset'\n",
    "missing_numbers = count_missing_numbers(folder_path)\n",
    "print(f\"Missing numbers in filenames: {missing_numbers}\")\n",
    "print(len(missing_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of true rows: 1655\n",
      "Number of false rows: 1655\n",
      "Number of rows in train.csv: 2398\n",
      "Number of rows in val.csv: 394\n",
      "Number of rows in test.csv: 518\n",
      "Sums to: 3310\n"
     ]
    }
   ],
   "source": [
    "# count number of true and false rows in csvs\n",
    "import pandas as pd\n",
    "true_df = pd.read_csv('dataset_only_true.csv')\n",
    "false_df = pd.read_csv('dataset_only_false.csv')\n",
    "\n",
    "print(f\"Number of true rows: {len(true_df)}\")\n",
    "print(f\"Number of false rows: {len(false_df)}\")\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('original_ELCo_dataset/train.csv')\n",
    "val_df = pd.read_csv('original_ELCo_dataset/val.csv')\n",
    "test_df = pd.read_csv('original_ELCo_dataset/test.csv')\n",
    "\n",
    "print(f\"Number of rows in train.csv: {len(train_df)}\")\n",
    "print(f\"Number of rows in val.csv: {len(val_df)}\")\n",
    "print(f\"Number of rows in test.csv: {len(test_df)}\")\n",
    "print(f\"Sums to: {len(train_df) + len(val_df) + len(test_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
