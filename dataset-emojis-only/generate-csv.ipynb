{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import os\n",
    "import cv2\n",
    "import grapheme\n",
    "import numpy as np\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing utility functions\n",
    "* `list[emoji]` -> `str` \n",
    "* `str` -> `list[emoji]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜‹ðŸž\n",
      "U+1F3B7\n",
      "necktie [EM] chart_increasing.\n",
      "[':necktie:', ':chart_increasing:']\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import ast\n",
    "\n",
    "def emoji_to_unicode(emoji_str):\n",
    "    return ' '.join([f\"U+{ord(char):X}\" for char in emoji_str])\n",
    "\n",
    "def process_emoji_list_to_str(emoji_list):\n",
    "    desc_processed = ' [EM] '.join(desc.strip(':') for desc in emoji_list)\n",
    "    return f\"{desc_processed}.\"\n",
    "\n",
    "def unprocess_emoji_list_from_str(emoji_str):\n",
    "    s = emoji_str[:-1].split(' [EM] ')\n",
    "    return [f\":{desc}:\" for desc in s]\n",
    "\n",
    "def emoji_str_from_description(desc_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a description string containing emoji descriptions into a string of actual emojis.\n",
    "    Args:\n",
    "        desc_str (str): A string containing emoji descriptions separated by ' [EM] '.\n",
    "                        The string is expected to start with \"This is\" and end with a period (\".\").\n",
    "\n",
    "    Returns:\n",
    "        str: A string of emojis corresponding to the descriptions in the input string.\n",
    "\n",
    "    Example:\n",
    "        >>> emoji_str_from_description('This is face_savoring_food [EM] bread.')\n",
    "        'ðŸ˜‹ðŸž'\n",
    "    \"\"\"\n",
    "    desc_str = desc_str[8:-1]  # Remove \"This is\" at the start and \".\" at the end\n",
    "    desc_list = desc_str.split(' [EM] ')  # Split the string into a list of descriptions\n",
    "    return ''.join([emoji.emojize(f\":{desc}:\") for desc in desc_list])  # Convert descriptions to emojis\n",
    "\n",
    "# write some tests for processing and unprocessingðŸ“ˆ\n",
    "print(emoji_str_from_description('This is face_savoring_food [EM] bread.'))\n",
    "print(emoji_to_unicode('ðŸŽ·'))\n",
    "print(process_emoji_list_to_str([':necktie:', ':chart_increasing:']))\n",
    "print(unprocess_emoji_list_from_str(process_emoji_list_to_str([':necktie:', ':chart_increasing:'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import os\n",
    "\n",
    "def generate_csv(input_file_path, output_file_path):\n",
    "    with open(input_file_path, newline='', encoding='utf-8') as fin, \\\n",
    "        open(output_file_path, 'w', newline='', encoding='utf-8') as fout:\n",
    "\n",
    "        reader = csv.DictReader(fin)\n",
    "        fieldnames = ['sent1', 'sent2', 'label', 'strategy'] # needs to have the same fieldnames in the output csv\n",
    "        writer = csv.DictWriter(fout, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in reader:\n",
    "            em = emoji_str_from_description(row['sent1'])\n",
    "            en = ' '.join(row['sent2'].split()[2:])[:-1] \n",
    "            writer.writerow({\n",
    "                'sent1': em,\n",
    "                'sent2': en,\n",
    "                'label': row['label'],\n",
    "                'strategy': row['strategy'],\n",
    "            })\n",
    "\n",
    "    print(f\"Conversion complete! Output saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dict contains fields not in fieldnames: 'sent1', 'sent2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      1\u001b[39m csvs_to_generate = [\n\u001b[32m      2\u001b[39m     (\n\u001b[32m      3\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m      os.path.join(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mconverted\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mval.csv\u001b[39m\u001b[33m'\u001b[39m)), \n\u001b[32m     14\u001b[39m ]\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m folder_type, \u001b[38;5;28minput\u001b[39m, output \u001b[38;5;129;01min\u001b[39;00m csvs_to_generate:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[43mgenerate_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mgenerate_csv\u001b[39m\u001b[34m(input_file_path, output_file_path)\u001b[39m\n\u001b[32m     15\u001b[39m         em = emoji_str_from_description(row[\u001b[33m'\u001b[39m\u001b[33msent1\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     16\u001b[39m         en = \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(row[\u001b[33m'\u001b[39m\u001b[33msent2\u001b[39m\u001b[33m'\u001b[39m].split()[\u001b[32m2\u001b[39m:])[:-\u001b[32m1\u001b[39m] \n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m         \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwriterow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msent1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msent2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43men\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstrategy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstrategy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConversion complete! Output saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/csv.py:154\u001b[39m, in \u001b[36mDictWriter.writerow\u001b[39m\u001b[34m(self, rowdict)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwriterow\u001b[39m(\u001b[38;5;28mself\u001b[39m, rowdict):\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.writer.writerow(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dict_to_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrowdict\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/csv.py:149\u001b[39m, in \u001b[36mDictWriter._dict_to_list\u001b[39m\u001b[34m(self, rowdict)\u001b[39m\n\u001b[32m    147\u001b[39m     wrong_fields = rowdict.keys() - \u001b[38;5;28mself\u001b[39m.fieldnames\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wrong_fields:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdict contains fields not in fieldnames: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    150\u001b[39m                          + \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28mrepr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m wrong_fields]))\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (rowdict.get(key, \u001b[38;5;28mself\u001b[39m.restval) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fieldnames)\n",
      "\u001b[31mValueError\u001b[39m: dict contains fields not in fieldnames: 'sent1', 'sent2'"
     ]
    }
   ],
   "source": [
    "csvs_to_generate = [\n",
    "    (\n",
    "     'train',\n",
    "     os.path.join('.', 'originals', 'train.csv'), \n",
    "     os.path.join('.', 'converted', 'train.csv')), \n",
    "\n",
    "    ('test',\n",
    "     os.path.join('.', 'originals', 'test.csv'), \n",
    "     os.path.join('.', 'converted', 'test.csv')), \n",
    "\n",
    "    ('val',\n",
    "     os.path.join('.', 'originals', 'val.csv'), \n",
    "     os.path.join('.', 'converted', 'val.csv')), \n",
    "]\n",
    "\n",
    "for folder_type, input, output in csvs_to_generate:\n",
    "    generate_csv(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of skipped_indices['train']: 57\n",
      "Length of skipped_indices['test']: 25\n",
      "Length of skipped_indices['val']: 10\n",
      "{'train': {1664, 386, 2309, 1542, 1031, 394, 2317, 2318, 2321, 402, 2324, 2326, 2328, 281, 1187, 422, 2343, 1448, 2346, 2348, 2351, 1586, 2356, 311, 1594, 2238, 2241, 1606, 1607, 971, 1109, 1111, 475, 1116, 1117, 1118, 1119, 1121, 1122, 1636, 1125, 1127, 1129, 1131, 1133, 1134, 367, 879, 880, 882, 1135, 1136, 1138, 1651, 2038, 1659, 2045}, 'test': {136, 26, 292, 42, 325, 335, 341, 342, 346, 349, 224, 225, 104, 106, 107, 108, 109, 362, 111, 492, 495, 114, 116, 246, 248}, 'val': {352, 354, 356, 200, 203, 23, 24, 155, 350, 351}}\n"
     ]
    }
   ],
   "source": [
    "for key, value in skipped_indices.items():\n",
    "    print(f\"Length of skipped_indices['{key}']: {len(value)}\")\n",
    "print(skipped_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensures csv rows match the image folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match for train: CSV rows = 2341, Images = 2341\n",
      "Match for test: CSV rows = 493, Images = 493\n",
      "Match for val: CSV rows = 384, Images = 384\n"
     ]
    }
   ],
   "source": [
    "for folder_type, _, output_csv, img_folder in csvs_to_generate:\n",
    "    # Count the number of rows in the CSV file\n",
    "    with open(output_csv, 'r', encoding='utf-8') as csv_file:\n",
    "        csv_row_count = sum(1 for _ in csv_file) - 1  # Subtract 1 for the header row\n",
    "\n",
    "    # Count the number of image files in the folder\n",
    "    img_file_count = len([f for f in os.listdir(img_folder) if os.path.isfile(os.path.join(img_folder, f))])\n",
    "\n",
    "    # Compare the counts\n",
    "    if csv_row_count != img_file_count:\n",
    "        print(f\"Mismatch for {folder_type}: CSV rows = {csv_row_count}, Images = {img_file_count}\")\n",
    "    else:\n",
    "        print(f\"Match for {folder_type}: CSV rows = {csv_row_count}, Images = {img_file_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
