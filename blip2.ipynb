{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/huggingface/peft.git transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from transformers import Blip2ForConditionalGeneration, Blip2Processor\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def load_model():\n",
    "    model = Blip2ForConditionalGeneration.from_pretrained(\n",
    "        \"Salesforce/blip2-opt-2.7b\", torch_dtype=torch.float16\n",
    "    )\n",
    "    processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "    \n",
    "    lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.1,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    )\n",
    "    \n",
    "    model = get_peft_model(model, lora_config)\n",
    "    return model, processor\n",
    "\n",
    "class Blip2Dataset(Dataset):\n",
    "    def __init__(self, csv_path, processor, image_dir):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.processor = processor\n",
    "        self.image_dir = image_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image_path = f\"{self.image_dir}/{row['image']}\"\n",
    "        em, en, label = row['EM'], row['EN'], row['label']\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\").resize((224, 224))\n",
    "        except FileNotFoundError:\n",
    "            return None\n",
    "        \n",
    "        answer = \"Yes\" if label == 1 else \"No\"\n",
    "        caption = f\"Question: does {em} entail {en}? Yes or no only. Answer: {answer}\"\n",
    "        inputs = self.processor(images=image, text=caption, return_tensors=\"pt\", padding=True)\n",
    "        \n",
    "        return {\"input_ids\": inputs.input_ids.squeeze(0), \"pixel_values\": inputs.pixel_values.squeeze(0), \"label\": torch.tensor(label, dtype=torch.long)}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    if not batch:\n",
    "        return None\n",
    "    input_ids = torch.stack([b[\"input_ids\"] for b in batch])\n",
    "    pixel_values = torch.stack([b[\"pixel_values\"] for b in batch])\n",
    "    labels = torch.stack([b[\"label\"] for b in batch])\n",
    "    return {\"input_ids\": input_ids, \"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "def load_dataset(csv_path=\"dataset.csv\", image_dir=\"CS4248_project/dataset_following_elco_split\"):\n",
    "    processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "    dataset = Blip2Dataset(csv_path, processor, image_dir)\n",
    "    return DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "def train(model, train_loader, epochs=3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            if batch is None:\n",
    "                continue\n",
    "            input_ids, pixel_values, labels = batch[\"input_ids\"].to(device), batch[\"pixel_values\"].to(device), batch[\"labels\"].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, pixel_values=pixel_values, labels=input_ids)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "def inference(model, processor, test_csv, image_dir):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    data = pd.read_csv(test_csv)\n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        image_path = f\"{image_dir}/{row['image']}\"\n",
    "        em, en, label = row['EM'], row['EN'], row['label']\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\").resize((224, 224))\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        \n",
    "        prompt = f\"Question: does {em} entail {en}? Yes or no only. Answer:\"\n",
    "        inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "        \n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=10)\n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip().lower()\n",
    "        pred = 1 if \"yes\" in generated_text else 0\n",
    "        \n",
    "        y_true.append(label)\n",
    "        y_pred.append(pred)\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "model, processor = load_model()\n",
    "train_loader = load_dataset()\n",
    "train(model, train_loader)\n",
    "model.save_pretrained(\"./blip2_lora_finetuned\")\n",
    "processor.save_pretrained(\"./blip2_lora_finetuned\")\n",
    "\n",
    "inference(model, processor, \"CS4248_project/dataset_following_elco_split/generated_img_dataset/test.csv\", \"CS4248_project/dataset_following_elco_split\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
