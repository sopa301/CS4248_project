{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "necktie [EM] chart_increasing.\n",
      "[':necktie:', ':chart_increasing:']\n"
     ]
    }
   ],
   "source": [
    "# Function to convert emojis to Unicode\n",
    "def emoji_to_unicode(emoji_str):\n",
    "    return ' '.join([f\"U+{ord(char):X}\" for char in emoji_str])\n",
    "\n",
    "def process_emoji_list_to_str(emoji_list):\n",
    "    desc_processed = ' [EM] '.join(desc.strip(':') for desc in emoji_list)\n",
    "    return f\"{desc_processed}.\"\n",
    "\n",
    "def unprocess_emoji_list_from_str(emoji_str):\n",
    "    s = emoji_str[:-1].split(' [EM] ')\n",
    "    return [f\":{desc}:\" for desc in s]\n",
    "\n",
    "import ast\n",
    "# write some tests for processing and unprocessing\n",
    "desc_list = ast.literal_eval(\"[':necktie:', ':chart_increasing:']\")\n",
    "print(process_emoji_list_to_str(desc_list))\n",
    "print(unprocess_emoji_list_from_str(process_emoji_list_to_str(desc_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete! Output saved to dataset_only_true.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import ast\n",
    "\n",
    "input_csv = 'ELCo.csv'\n",
    "output_csv = 'dataset_only_true.csv'\n",
    "\n",
    "\n",
    "with open(input_csv, newline='', encoding='utf-8') as fin, \\\n",
    "     open(output_csv, 'w', newline='', encoding='utf-8') as fout:\n",
    "\n",
    "    reader = csv.DictReader(fin)\n",
    "\n",
    "    # Update fieldnames to include all keys in writer.writerow()\n",
    "    fieldnames = ['sent1', 'sent2', 'unicode', 'label', 'strategy', 'attribute', 'filename', 'emoji']\n",
    "    writer = csv.DictWriter(fout, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    i = 0\n",
    "    for row in reader:\n",
    "        desc_list = ast.literal_eval(row['Description'])  # Convert string to list \n",
    "\n",
    "        sent1 = process_emoji_list_to_str(desc_list)\n",
    "        sent2 = row['EN']\n",
    "\n",
    "        label = 1\n",
    "\n",
    "        unicode_repr = emoji_to_unicode(row['EM'])\n",
    "\n",
    "        writer.writerow({\n",
    "            'sent1': sent1,\n",
    "            'sent2': sent2,\n",
    "            'unicode': unicode_repr,  # Added this to match fieldnames\n",
    "            'label': label,\n",
    "            'strategy': row['Composition strategy'],\n",
    "            'attribute': row['Attribute'],\n",
    "            'filename': f\"{i}.png\",\n",
    "            'emoji': row['EM'],\n",
    "        })\n",
    "\n",
    "        i += 1\n",
    "\n",
    "print(f\"Conversion complete! Output saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete! Output saved to dataset_only_false.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "input_csv_folder = 'original_ELCo_dataset'\n",
    "input_csvs = ['train.csv', 'val.csv', 'test.csv']\n",
    "output_csv = 'dataset_only_false.csv'\n",
    "reference_csv = 'ELCo_no_punctuation.csv'\n",
    "\n",
    "elco_df = pd.read_csv(reference_csv)\n",
    "\n",
    "with open(output_csv, 'w', newline='', encoding='utf-8') as fout:\n",
    "  \n",
    "    fieldnames = ['sent1', 'sent2', 'unicode', 'label', 'strategy', 'attribute', 'filename', 'emoji']\n",
    "    writer = csv.DictWriter(fout, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for input_csv in input_csvs:\n",
    "        with open(f\"{input_csv_folder}/{input_csv}\", newline='', encoding='utf-8') as fin:\n",
    "            reader = csv.DictReader(fin)\n",
    "\n",
    "            for row in reader:\n",
    "                if row['label'] == '1':\n",
    "                    continue\n",
    "                \n",
    "\n",
    "                sent1 = row['sent1']\n",
    "                # strip the 'this is ' prefix\n",
    "                tmp = sent1[8:]\n",
    "                # unprocess the emoji string\n",
    "                tmp = str(unprocess_emoji_list_from_str(tmp))\n",
    "\n",
    "                # get the unique row index of elco_df where the Description field matches tmp\n",
    "                elco_row = elco_df[elco_df['Description'] == tmp].index[0]\n",
    "\n",
    "                sent2 = row['sent2']\n",
    "                label = 0\n",
    "                unicode_repr = emoji_to_unicode(elco_df.loc[elco_row, 'EM'])\n",
    "\n",
    "                writer.writerow({\n",
    "                    'sent1': sent1,\n",
    "                    'sent2': sent2,\n",
    "                    'unicode': unicode_repr,\n",
    "                    'label': label,\n",
    "                    'strategy': elco_df.loc[elco_row, 'Composition strategy'],\n",
    "                    'attribute': elco_df.loc[elco_row, 'Attribute'],\n",
    "                    'filename': f\"{elco_row}.png\",\n",
    "                    'emoji': elco_df.loc[elco_row, 'EM'],\n",
    "                })\n",
    "\n",
    "print(f\"Conversion complete! Output saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utility stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing numbers in filenames: [26, 42, 375, 376, 488, 544, 566, 622, 630, 638, 1343, 1521, 1523, 1528, 1529, 1530, 1531, 1533, 1534, 1537, 1539, 1541, 1545, 1551, 1553, 1554, 1555, 1556, 1558]\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def count_missing_numbers(folder_path):\n",
    "  # Get a list of all files in the folder\n",
    "  files = os.listdir(folder_path)\n",
    "  \n",
    "  # Extract numbers from filenames and convert them to integers\n",
    "  numbers = sorted([int(f.split('.')[0]) for f in files if f.split('.')[0].isdigit()])\n",
    "  \n",
    "  # Find the missing numbers\n",
    "  missing_numbers = [num for num in range(numbers[0], numbers[-1] + 1) if num not in numbers]\n",
    "  \n",
    "  return missing_numbers\n",
    "\n",
    "folder_path = 'google_dataset'\n",
    "missing_numbers = count_missing_numbers(folder_path)\n",
    "print(f\"Missing numbers in filenames: {missing_numbers}\")\n",
    "print(len(missing_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of true rows: 1655\n",
      "Number of false rows: 1655\n",
      "Number of rows in train.csv: 2398\n",
      "Number of rows in val.csv: 394\n",
      "Number of rows in test.csv: 518\n",
      "Sums to: 3310\n"
     ]
    }
   ],
   "source": [
    "# count number of true and false rows in csvs\n",
    "import pandas as pd\n",
    "true_df = pd.read_csv('dataset_only_true.csv')\n",
    "false_df = pd.read_csv('dataset_only_false.csv')\n",
    "\n",
    "print(f\"Number of true rows: {len(true_df)}\")\n",
    "print(f\"Number of false rows: {len(false_df)}\")\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('original_ELCo_dataset/train.csv')\n",
    "val_df = pd.read_csv('original_ELCo_dataset/val.csv')\n",
    "test_df = pd.read_csv('original_ELCo_dataset/test.csv')\n",
    "\n",
    "print(f\"Number of rows in train.csv: {len(train_df)}\")\n",
    "print(f\"Number of rows in val.csv: {len(val_df)}\")\n",
    "print(f\"Number of rows in test.csv: {len(test_df)}\")\n",
    "print(f\"Sums to: {len(train_df) + len(val_df) + len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                               [👔, 📈]\n",
      "1                            [🏢, 🤑, 🤑]\n",
      "2                            [👨, 💻, 🤝]\n",
      "3       [🏢, 🧑, 🤝, 🧑, 🧑, 🤝, 🧑, 🧑, 🤝, 🧑]\n",
      "4                            [👩, 💻, 🤑]\n",
      "                     ...              \n",
      "1650                            [👍, 👣]\n",
      "1651                            [👏, 🪜]\n",
      "1652                         [😤, 🗣, 💬]\n",
      "1653                            [💨, 🤬]\n",
      "1654                         [👍, 👣, ➡]\n",
      "Name: emoji, Length: 3310, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import regex\n",
    "\n",
    "# Function to extract all emojis from a text string using Unicode properties.\n",
    "def extract_emojis(text):\n",
    "    emoji_pattern = regex.compile(r'\\p{Emoji}', flags=regex.UNICODE)\n",
    "    return emoji_pattern.findall(text) if isinstance(text, str) else []\n",
    "\n",
    "# Read the CSV files\n",
    "df_true = pd.read_csv('dataset_only_true.csv')\n",
    "df_false = pd.read_csv('dataset_only_false.csv')\n",
    "df = pd.concat([df_true, df_false])\n",
    "df_emoji = pd.read_csv('/home/andrew/CS4248_project/dataset/noto-emoji/emoji_dataset.csv')\n",
    "\n",
    "# Create a new column with the extracted emojis from the original 'emoji' column\n",
    "emojis = df['emoji'].apply(extract_emojis)\n",
    "print(emojis)\n",
    "file_name_list = []\n",
    "for emoji_list in emojis:\n",
    "    file_name = []\n",
    "    for emoji in emoji_list:\n",
    "        df_emoji_row = df_emoji[df_emoji['emoji'] == emoji]\n",
    "        if len(df_emoji_row) == 0:\n",
    "            print(f\"Emoji {emoji} not found in emoji dataset\")\n",
    "            continue\n",
    "        file_name.append(\"noto-emoji/png/512/\"+f\"{df_emoji_row['filename'].values[0]}\")\n",
    "    file_name_list.append(file_name)\n",
    "df['separate_filenames'] = file_name_list\n",
    "\n",
    "df.to_csv('merged_emoji.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
